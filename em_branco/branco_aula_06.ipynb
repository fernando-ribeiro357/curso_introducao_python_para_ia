{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":7030,"status":"ok","timestamp":1726604875681,"user":{"displayName":"Adriano Vasconcellos Soares","userId":"14599394622412668736"},"user_tz":180},"id":"msmti2Gmji7t","outputId":"c40f502a-16aa-4366-9ac0-5f724cea0314"},"outputs":[],"source":["!pip install langchain==0.3.0\n","!pip install langchain-groq==0.2.0"]},{"cell_type":"markdown","metadata":{"id":"UfBsPqTlOtZl"},"source":["# Aula 6: Criando nosso primeiro ChatBot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuUtqgmn4ZV0"},"outputs":[],"source":["import os\n","from langchain_groq import ChatGroq\n","from langchain.prompts import ChatPromptTemplate\n","\n","api_key = 'ADICIONE SUA API KEY DA GROQ'\n","os.environ['GROQ_API_KEY'] = api_key\n","\n","chat = ChatGroq(model='llama-3.1-70b-versatile')\n","\n","\n","def resposta_do_bot(lista_mensagens):\n","  template = ChatPromptTemplate.from_messages(\n","      [('system', 'VocÃª Ã© um assistente amigÃ¡vel chamado Asimo')] +\n","      lista_mensagens\n","  )\n","  chain = template | chat\n","  return chain.invoke({}).content\n","\n","print('Bem-vindo ao ChatBot da Asimo! (Digite x se vocÃª quiser sair!)\\n')\n","mensagens = []\n","while True:\n","  pergunta = input('UsuÃ¡rio: ')\n","  if pergunta.lower() == 'x':\n","    break\n","  mensagens.append(('user', pergunta))\n","  resposta = resposta_do_bot(mensagens)\n","  mensagens.append(('assistant', resposta))\n","  print(f'Bot: {resposta}')\n","\n","print('\\nMuito obrigado por utilizar o AsimoBot!')\n"]},{"cell_type":"markdown","metadata":{"id":"QILqGqsUY0cI"},"source":["## Trabalhando com templates de Prompts"]},{"cell_type":"markdown","metadata":{"id":"17gmkZ1Me0Ye"},"source":["### O que Ã© um prompt?"]},{"cell_type":"markdown","metadata":{"id":"wPrmdICIebLE"},"source":["Um prompt Ã© uma instruÃ§Ã£o ou uma solicitaÃ§Ã£o que vocÃª fornece a um modelo de linguagem para gerar uma resposta ou um texto. Ele serve como um ponto de partida para a interaÃ§Ã£o, orientando o modelo sobre o que vocÃª deseja que ele produza. Resumindo, o prompt Ã© a entrada na forma de texto que Ã© processada pelo modelo para geraÃ§Ã£o de uma resposta. Ele deve sempre ser claro e especÃ­fico.\n","\n","Para entender melhor, imagine que vocÃª estÃ¡ conversando com um chef de cozinha. Se vocÃª disser \"FaÃ§a algo gostoso\", o chef pode interpretar isso de vÃ¡rias maneiras, resultando em pratos diferentes. No entanto, se vocÃª especificar \"Prepare uma lasanha vegetariana\", o chef terÃ¡ uma direÃ§Ã£o clara e poderÃ¡ criar exatamente o que vocÃª deseja. Da mesma forma, um prompt bem formulado fornece ao modelo de linguagem uma orientaÃ§Ã£o precisa, permitindo que ele gere respostas mais relevantes e alinhadas com suas expectativas."]},{"cell_type":"markdown","metadata":{"id":"bHOhF0xmfDzU"},"source":["### O que Ã© um template de Prompt?"]},{"cell_type":"markdown","metadata":{"id":"RRvBrcDLY3lX"},"source":["Um template de prompt (ou PromptTemplate) Ã© uma estrutura prÃ©-definida que permite criar prompts de forma mais organizada e reutilizÃ¡vel ao interagir com modelos de linguagem. Ele funciona como um molde que pode ser preenchido com variÃ¡veis ou informaÃ§Ãµes especÃ­ficas, facilitando a geraÃ§Ã£o de prompts consistentes e adaptÃ¡veis para diferentes contextos ou tarefas. Ao utilizar um PromptTemplate, vocÃª pode economizar tempo e garantir que a formulaÃ§Ã£o do prompt siga um padrÃ£o desejado, o que pode melhorar a qualidade das respostas geradas pelo modelo. Essa abordagem Ã© especialmente Ãºtil em aplicaÃ§Ãµes onde vocÃª precisa gerar mÃºltiplos prompts semelhantes, como em chatbots como Ã© o nosso caso.\n","\n","Vamos a exemplos..."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"x_ijnY4CeGDw"},"outputs":[{"name":"stdout","output_type":"stream","text":["input_variables=['expressao', 'lingua'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['expressao', 'lingua'], input_types={}, partial_variables={}, template='Traduza \"{expressao}\" para {lingua}'), additional_kwargs={})]\n"]},{"data":{"text/plain":["ChatPromptValue(messages=[HumanMessage(content='Traduza \"Beleza?\" para inglÃªs', additional_kwargs={}, response_metadata={})])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.prompts import ChatPromptTemplate\n","\n","template = ChatPromptTemplate.from_messages(\n","    [('user', 'Traduza \"{expressao}\" para {lingua}')]\n",")\n","print(template)\n","template.invoke({'expressao': 'Beleza?', 'lingua': 'inglÃªs'})\n"]},{"cell_type":"markdown","metadata":{"id":"FvDP0KhljFHN"},"source":["Uma \"chain\" (ou cadeia) refere-se a uma sequÃªncia de operaÃ§Ãµes ou etapas que sÃ£o encadeadas para processar informaÃ§Ãµes e gerar resultados de forma estruturada. Cada etapa na chain pode envolver diferentes componentes, como prompts, modelos de linguagem, ferramentas de processamento de dados ou chamadas a APIs, permitindo que construamos fluxos de trabalho complexos e personalizados."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"WOkp-C2qeIrx"},"outputs":[{"name":"stdout","output_type":"stream","text":["A traduÃ§Ã£o de \"Beleza?\" para francÃªs Ã© \"D'accord?\" ou apenas \"D'accord\". No entanto, se vocÃª quiser uma traduÃ§Ã£o mais literal, seria \"BeautÃ©?\" ou \"C'est beau?\".\n","\n","Mas, se vocÃª estÃ¡ se referindo a um acordo ou concordÃ¢ncia, como em \"Ok, beleza\", a traduÃ§Ã£o mais comum seria \"D'accord\".\n"]}],"source":["import os\n","from langchain_groq import ChatGroq\n","from langchain.prompts import ChatPromptTemplate\n","\n","api_key = 'sua-api-key-aqui'\n","os.environ['GROQ_API_KEY'] = api_key\n","\n","chat = ChatGroq(model='llama-3.1-70b-versatile')\n","\n","template = ChatPromptTemplate.from_messages(\n","    [('user', 'Traduza \"{expressao}\" para a lÃ­ngua {lingua}')]\n",")\n","\n","chain = template | chat\n","\n","resposta = chain.invoke({'expressao': 'Beleza?', 'lingua': 'franceza'})\n","\n","print(resposta.content)"]},{"cell_type":"markdown","metadata":{"id":"UhGfgFH-pfL1"},"source":["## Continuando o projeto lÃ¡ da aula 3"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3RZ-kFklw2oL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bem vindo ao ChatBot. ðŸ¤– Como posso te ajudar?\n","\n","Saindo do ChatBot...\n","\n","Obrigado por me consultar, estarei sempre aqui para te ajudar. ðŸ¤–\n","\n"]}],"source":["import os\n","from langchain_groq import ChatGroq\n","from langchain.prompts import ChatPromptTemplate\n","\n","api_key = 'SUA CHAVE DA GROQ AQUI'\n","os.environ['GROQ_API_KEY'] = api_key\n","chat = ChatGroq(model='llama-3.1-70b-versatile')\n","\n","def resposta_bot(mensagens):\n","    mensagens_modelo = [('system', 'VocÃª Ã© um assistente amigÃ¡vel chamado Rodney Lataria')]\n","    mensagens_modelo += mensagens\n","    template = ChatPromptTemplate.from_messages(mensagens_modelo)\n","    chain = template | chat    \n","    return chain.invoke({}).content\n","\n","print('Bem vindo ao ChatBot. ðŸ¤– Como posso te ajudar?')\n","mensagens = []\n","while True:\n","    pergunta = input(f'[x: sair]\\nðŸ™‚ >>> ')\n","\n","    if pergunta.lower() == 'x':\n","        print('\\nSaindo do ChatBot...\\n')\n","        break\n","\n","    mensagens.append(('user', pergunta))\n","    resposta = resposta_bot(mensagens)\n","    mensagens.append(('assistant', resposta))\n","    print('''\n","    â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”€â”€â”€\n","    â”€â”€â–â–€â–€â–€â–€â–€â–€â–€â–€â–Œâ”€â”€\n","    â”€â–â–  â–€  â–€  â–Œâ–Œâ”€\n","    â”€â”€â–â”€â”€â–„â–„â–„â–„â”€â”€â–Œâ”€â”€\n","    â”€â”€â–  â–ˆâ–„â–„â–ˆ  â–Œâ”€â”€\n","    ''')\n","    print(f'>>> {resposta}\\n')\n","\n","print('Obrigado por me consultar, estarei sempre aqui para te ajudar. ðŸ¤–\\n')\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNdUJ4Pg1LRFu7Q4YmuZznX","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
